# خطوط أنابيب الاستعلام (Query Workflows)

<div dir="rtl">

<img src="https://docs.llamaindex.ai/en/stable/_static/query/pipeline_rag_example.png">

المصدر: [مستندات LlamaIndex](https://docs.llamaindex.ai/en/stable/module_guides/querying/pipeline/)

## نظرة عامة

LlamaIndex بيوفر واجهة برمجة Workflow API لربط الوحدات لإدارة سير عمل البيانات بسهولة. بيتمحور حوالين الـ Workflow، حيث بتربط وحدات مختلفة زي نماذج اللغة الكبيرة، وprompts، والمستَرجعات في تسلسل أو DAG للتنفيذ الشامل باستخدام الأحداث.

تقدر تبسط سير العمل بكفاءة باستخدام Workflow، بتقلل تعقيد الكود وبتحسن القراءة. بالإضافة لكده، واجهة تصريحية بتضمن سهولة تسلسل مكونات سير العمل للقابلية للنقل والنشر عبر الأنظمة في المستقبل.

## سير عمل RAG مع PromptTemplate

هبدأ بسير عمل معقد شوية حيث المدخل بيمر عبر اتنين prompts قبل بدء الاسترجاع.

### خطوات سير العمل:

1. استرجاع سؤال عن موضوع معين
2. إعادة صياغة السياق

كل prompt بياخد مدخل واحد بس، فالـ `Workflow` هيربط تلقائياً مخرجات اللغة الكبيرة في الprompt وبعدين في اللغة الكبيرة باستخدام الأحداث.

هتشوف إزاي تحدد تدفقات الأحداث بشكل أكثر وضوحاً في القسم اللي جاي.

## سير عمل RAG تاني

هنا بننشئ سير عمل RAG بدون خطوة إعادة كتابة الاستعلام.

هنا محتاجين طريقة لربط استعلام المدخل بالمستَرجع والملخص.

نقدر نعمل ده عن طريق تعريف أحداث ممكن تستهلكها خطوات متعددة، بيسمح لنا نربط المدخلات بوحدات متعددة في الاتجاه السفلي.

### ملاحظات مهمة

- سير العمل متكوّن فعلاً بالخطوات وتدفقات الأحداث
- مش محتاج إضافة وحدات يدوياً وربطها زي في QueryPipeline
- الروتينج التلقائي للأحداث مكوّن

</div>
