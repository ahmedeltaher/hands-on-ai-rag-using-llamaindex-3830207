# ุชุญุณูู ุญุฌู ุงููุทุน (Chunk Size)

<div dir="rtl">

ูู ุงูุฏุฑุณ ุฏูุ ููุณุชูุดู ุฅูู ูู ุงูุชูุทูุน (chunking)ุ ูุฅุฒุงู ุจูุฃุซุฑ ุนูู ุนูููุฉ ุงูููุฑุณุฉ ูุงูุงุณุชุฑุฌุงุนุ ูุฅุฒุงู ุชูุฏุฑ ุชุฎุตุต ุญุฌู ุงููุทุนุฉ ูุงูุชุฏุงุฎู ุจูููู ุนุดุงู ุชุญุณู ุงููุชุงุฆุฌ.

> **ูุตูุฉ ุงูุชูุทูุน:** ูุฏูู ูุด ุฅูู ุชูุทุน ุนุดุงู ุงูุชูุทูุน ููุณูุ ูุฏููุง ุฅููุง ูุฌูุฒ ุงูุจูุงูุงุช ุจุชุงุนุชูุง ุจุดูู ูุฎูููุง ุชุชุณุชุฑุฌุน ุจูููุฉ ุจุนุฏูู.
>
> -- Greg Kamradtุ [5 ูุณุชููุงุช ูุชูุณูู ุงููุตูุต](https://github.com/FullStackRetrieval-com/RetrievalTutorials/blob/main/tutorials/LevelsOfTextSplitting/5_Levels_Of_Text_Splitting.ipynb)

## ููู ุงูุชูุทูุน (Chunking)

ููุง ุงููุณุชูุฏุงุช ุจุชุชุญุท ูู ุงูููุฑุณ (index)ุ `LlamaIndex` ุจููุณููุง ููุทุน ุฃุตุบุฑ ุงุณููุง "chunks". ุงูุนูููุฉ ุฏู ุงุณููุง ุงูุชูุทูุน (chunking). ุจุดูู ุงูุชุฑุงุถูุ LlamaIndex ุจูุณุชุฎุฏู *ุญุฌู ูุทุนุฉ* 1024 ู*ุชุฏุงุฎู ุจูู ุงููุทุน* 20.

ุจุณ ุงูุฃุฑูุงู ุฏู ูุนูุงูุง ุฅููุ ูุฅุฒุงู ุจุชุฃุซุฑ ุนูู ุนูููุฉ ุงูููุฑุณุฉ ูุงูุงุณุชุฑุฌุงุนุ

### ุญุฌู ุงููุทุนุฉ (Chunk Size)

ุญุฌู ุงููุทุนุฉ ุจูุญุฏุฏ ุฃูุตู ุนุฏุฏ ูู ุงูุฑููุฒ (tokens) (ุงููู ุชูุฑูุจุงู ุชุณุงูู ุงููููุงุช) ุงููู ูู ูุทุนุฉ ูุชุญุชูู ุนูููุง. ุจุญุฌู ูุทุนุฉ ุงูุชุฑุงุถู 1024ุ `LlamaIndex` ูููุณู ุงููุณุชูุฏุงุช ุจุชุงุนุชู ููุทุน ุทูููุง ูุด ุฃูุชุฑ ูู 1024 ุฑูุฒ.

#### **๐ค ุญุฌู ุงููุทุนุฉ ุงูุตุบูุฑ**

* ุชุถูููุงุช (embeddings) ุฃูุชุฑ ุฏูุฉ ูุชุฑููุฒ
* ูููุฏ ูุงุณุชุฑุฌุงุน ูุนูููุงุช ูุญุฏุฏุฉ

#### **๐ ุญุฌู ุงููุทุนุฉ ุงููุจูุฑ**

* ุชุถูููุงุช ุนุงูุฉ ุฃูุชุฑ ูุน ุณูุงู ุฃูุณุน
* ูููุฏ ููุธุฑุฉ ุนุงูุฉ ุนูู ุงููุณุชูุฏุงุชุ ุจุณ ูููู ูููุช ุชูุงุตูู

### ุงูุชุฏุงุฎู ุจูู ุงููุทุน (Chunk Overlap)

* ุฑููุฒ ูุดุชุฑูุฉ ุจูู ุงููุทุน ุงููุชุฌุงูุฑุฉ (ุงูุชุฑุงุถู: 20)
* ุจูุญุงูุธ ุนูู ุงูุณูุงู ููููุน ููุฏุงู ุงููุนูููุงุช

ุฃูุตุญู ุชุจุต ุนูู [ุฃุฏุงุฉ ุชุตูุฑ ุงููุทุน ุฏู](https://huggingface.co/spaces/m-ric/chunk_visualizer) ุนุดุงู ุชููู ุจุดูู ุจุฏููู ุญุฌู ุงููุทุนุฉ ูุงูุชุฏุงุฎู.

## ๐ค ุชุฃุซูุฑ ุญุฌู ุงููุทุนุฉ

ุฃูุตุญู ุชูุฑุฃ [ุงูููุงู ุฏู](https://www.llamaindex.ai/blog/evaluating-the-ideal-chunk-size-for-a-rag-system-using-llamaindex-6207e5d3fec5) ูู ูุฑูู LlamaIndex.

#### **๐ ุงูููุงุกูุฉ ูุงูุชูุตูู**

* ุงููุทุน ุงูุตุบูุฑุฉ (ูุซูุงูุ 128) ุจุชููุฑ ุชูุงุตูู ุจุณ ุจุชุฎุงุทุฑ ุจููุฏุงู ูุนูููุงุช ูููุฉุ ุฃู ููุต ูู ุงูุณูุงู ุงููุงูู.
* ุงููุทุน ุงููุจูุฑุฉ (ูุซูุงูุ 512) ุฃูุชุฑ ุงุญุชูุงูุงู ุฅููุง ุชูุชูุท ุงูุณูุงู ุงููุงุฒูุ ุจุณ ููุงู ูููุง ุฎุทุฑ ุฅููุง ุชุดูู ูุนูููุงุช ูุด ุฐุงุช ุตูุฉ.
* ููุงููุณ ุงูุฏูุฉ (Faithfulness) ูุงูููุงุกูุฉ (Relevancy) ุจุชุณุงุนุฏ ูู ุชูููู ุฌูุฏุฉ ุงูุงุณุชุฌุงุจุฉ.

#### **๐ฏ ุญุฌู ุงููุทุนุฉ ูุญุงูุฉ ุงูุงุณุชุฎุฏุงู**

* **ุงูุฅุฌุงุจุฉ ุนูู ุงูุฃุณุฆูุฉ:** ูุทุน ุฃูุตุฑ ููุญุฏุฏุฉ ููุฅุฌุงุจุงุช ุงูุฏูููุฉ.
* **ุงูุชูุฎูุต:** ูุทุน ุฃุทูู ูุงูุชูุงุท ุงูุณูุงู ุงูุนุงู.

#### **โณ ููุช ุชูููุฏ ุงูุงุณุชุฌุงุจุฉ**

* ุงููุทุน ุงููุจูุฑุฉ ุจุชููุฑ ุณูุงู ุฃูุชุฑ ุจุณ ูููู ุชุจุทุฆ ุงููุธุงู.
* ุงูููุงุฒูุฉ ุจูู ุงูุดููููุฉ ูุงูุณุฑุนุฉ ูููุฉ ุฌุฏุงู.

#### **โ๏ธ ุฅูุฌุงุฏ ุงูุญุฌู ุงูุฃูุซู**

* ุงุฎุชุจุงุฑ ุฃุญุฌุงู ูุทุน ูุฎุชููุฉ ุถุฑูุฑู ูุญุงูุงุช ุงูุงุณุชุฎุฏุงู ููุฌููุนุงุช ุงูุจูุงูุงุช ุงููุญุฏุฏุฉ.
* ุงูููุงุฒูุฉ ุจูู ุงูุชูุงุท ุงููุนูููุงุช ูุงูููุงุกุฉ ูู ุงูููุชุงุญ.

### ุงุนุชุจุงุฑุงุช ุนูุฏ ุชุฎุตูุต ุญุฌู ุงููุทุนุฉ

ููุง ุชูุฑุฑ ุญุฌู ุงููุทุนุฉุ ูู ุญุงุฌุงุช ูุงุฒู ุชุงุฎุฏ ุจุงูู ูููุง:

| ุงูุนุงูู | ุงููุตู |
|--------|-------|
| ๐ **ุฎุตุงุฆุต ุงูุจูุงูุงุช** | ุญุฌู ุงููุทุนุฉ ุงูุฃูุซู ุจูุนุชูุฏ ุนูู ุงูุจูุงูุงุช ุงููู ุจุชููุฑุณูุง. ุงููุณุชูุฏุงุช ุงูุทูููุฉ ูุงูููุตูุฉุ ูููู ุชุญุชุงุฌ ุญุฌู ูุทุนุฉ ุฃูุจุฑ ุนุดุงู ุชูุชูุท ุณูุงู ุฃูุชุฑ. ุญุฌู ุงููุทุนุฉ ุงูุฃุตุบุฑ ูููู ูููู ุฃูุณุจ ููููุฑุงุช ุงููุตูุฑุฉ ูุงููุฑูุฒุฉ. |
| ๐ **ูุชุทูุจุงุช ุงูุงุณุชุฑุฌุงุน** | ูู ูุญุชุงุฌ ุชุณุชุฑุฌุน ุชูุงุตูู ูุญุฏุฏุฉ ุฌุฏุงูุ ุญุฌู ูุทุนุฉ ุฃุตุบุฑ ูููู ูููู ุฃุญุณู. ูู ุจุชุฏูุฑ ุนูู ูุนูููุงุช ุนุงูุฉ ุฃูุชุฑุ ุญุฌู ูุทุนุฉ ุฃูุจุฑ ูููู ูููู. |
| ๐ข **ูุนุงููุงุช ุงูุชุดุงุจู** | ูุน ุญุฌู ูุทุนุฉ ุฃุตุบุฑุ ุงูุชุถูููุงุช ุจุชุจูู ุฃูุชุฑ ุชุญุฏูุฏุงูุ ููุชูุฌุฉ ููุฏูุ ูููู ูููู ูู ูุทุน ุฐุงุช ุตูุฉ ุฃูุชุฑ ุจุชุทุงุจู ุงุณุชุนูุงู ูุนูู. ูุงุณุชูุนุงุจ ุงูุฒูุงุฏุฉ ุฏู ูู ุงููุทุน ุงููุญุชููุฉ ุฐุงุช ุงูุตูุฉุ ูููุตุญ ุจุฒูุงุฏุฉ ูุนุงูู `similarity_top_k`. ุงูุชุนุฏูู ุฏู ุจูุถูู ุฅู ูุญุฑู ุงูุงุณุชุนูุงู ูุงูุบููุด ูุชุงุฆุฌ ุฐุงุช ุตูุฉ ุจุณุจุจ ุงุฎุชูุงุฑ ุถูู ุฌุฏุงู ููุนูุงุตุฑ ุงูุฃุนูู. |

### ูู [ุทุฑู ูุฎุชููุฉ](https://docs.llamaindex.ai/en/stable/module_guides/loading/node_parsers/modules) ุชูุฏุฑ ุชุณุชุฎุฏููุง ูุชูุทูุน ุงููุณุชูุฏุงุช ุจุชุงุนุชู.

| ููุน ุงููุญูู | ุงุณู ุงูููุณู | ุงููุตู |
|-----------|-----------|-------|
| ๐ ูุญููุงุช ุงูุนูุฏ ุงููุจููุฉ ุนูู ุงููููุงุช | ๐`SimpleFileNodeParser` | ุฃุจุณุท ูุณุงุฑ: `FlatFileReader` + `SimpleFileNodeParser` ุงููู ุจูุณุชุฎุฏููุง ุชููุงุฆูุงู ุฃุญุณู ูุญูู ุนูุฏ ููู ููุน ูุญุชูู. ุจุนุฏููุ ูููู ุชุนูู ุณูุณูุฉ ูู ูุญูู ุงูุนูุฏ ุงููุจูู ุนูู ุงููููุงุช ูุน ูุญูู ุนูุฏ ูุจูู ุนูู ุงููุต ูุญุณุงุจ ุงูุทูู ุงููุนูู ูููุต. |
| | ๐`HTMLNodeParser` | ุงููุญูู ุฏู ุจูุณุชุฎุฏู beautifulsoup ูุชุญููู HTML ุงูุฎุงู. ุจุดูู ุงูุชุฑุงุถูุ ููุญูู ูุฌููุนุฉ ูุฎุชุงุฑุฉ ูู ูุณูู HTMLุ ุจุณ ุชูุฏุฑ ุชุบูุฑูุง. ุงููุณูู ุงูุงูุชุฑุงุถูุฉ ูู: ["p", "h1", "h2", "h3", "h4", "h5", "h6", "li", "b", "i", "u", "section"] |
| | ๐ญ`JSONNodeParser` | ุงูู `JSONNodeParser` ุจูุญูู JSON ุงูุฎุงู. |
| | ๐`MarkdownNodeParser` | ุงูู `MarkdownNodeParser` ุจูุญูู ูุต markdown ุงูุฎุงู. |
| โ๏ธ ููุณูุงุช ุงููุตูุต | ๐ป`CodeSplitter` | ุจููุณู ูุต ุงูููุฏ ุงูุฎุงู ุจูุงุกู ุนูู ุงููุบุฉ ุงูููุชูุจ ุจููุง. |
| | ๐ฆ๐`LangchainNodeParser` | ุชูุฏุฑ ููุงู ุชูู ุฃู ููุณู ูุต ููุฌูุฏ ูู langchain ุจูุญูู ุนูุฏ. |
| | ๐`SentenceSplitter` | ุงูู `SentenceSplitter` ุจูุญุงูู ููุณู ุงููุต ูุน ุงุญุชุฑุงู ุญุฏูุฏ ุงูุฌูู. |
| | ๐ช`SentenceWindowNodeParser` | ุงูู `SentenceWindowNodeParser` ุจููุณู ูู ุงููุณุชูุฏุงุช ูุฌูู ูุฑุฏูุฉ. ุงูุนูุฏ ุงููุงุชุฌุฉ ููุงู ุจุชุญุชูู ุนูู "ูุงูุฐุฉ" ูุญูุทุฉ ูู ุงูุฌูู ุญูุงููู ูู ุนูุฏุฉ ูู ุงูุจูุงูุงุช ุงููุตููุฉ. |
| | ๐ง`SemanticSplitterNodeParser` | ุจุฏู ุชูุทูุน ุงููุต ุจุญุฌู ูุทุนุฉ ุซุงุจุชุ ุงูููุณู ุงูุฏูุงูู ุจูุฎุชุงุฑ ููุทุฉ ุงููุตู ุจูู ุงูุฌูู ุจุดูู ุชูููู ุจุงุณุชุฎุฏุงู ุชุดุงุจู ุงูุชุถูููุงุช. ุฏู ุจูุถูู ุฅู "ุงููุทุนุฉ" ุจุชุญุชูู ุนูู ุฌูู ูุฑุชุจุทุฉ ุฏูุงููุงู ุจุจุนุถูุง. |
| | ๐ช`TokenTextSplitter` | ุงูู `TokenTextSplitter` ุจูุญุงูู ููุณู ูุญุฌู ูุทุนุฉ ูุชุณู ุญุณุจ ุนุฏุฏ ุงูุฑููุฒ ุงูุฎุงู. |
| ๐ ูุญููุงุช ุงูุนูุฏ ุงููุจููุฉ ุนูู ุงูุนูุงูุงุช | ๐ฟ`HierarchicalNodeParser` | ูุญูู ุงูุนูุฏ ุฏู ูููุทุน ุงูุนูุฏ ูุนูุฏ ูุฑููุฉ. ุฏู ูุนูุงู ุฅู ูุฏุฎู ูุงุญุฏ ููุชูุทุน ูุนุฏุฉ ูุณุชููุงุช ูุฑููุฉ ูู ุฃุญุฌุงู ุงููุทุนุ ูุน ูู ุนูุฏุฉ ุจุชุญุชูู ุนูู ูุฑุฌุน ููุนูุฏุฉ ุงูุฃู ุจุชุงุนุชูุง. |

## ููุฑูุฒ ุจุณ ุนูู ุดููุฉ ุงุณุชุฑุงุชูุฌูุงุช

ููุฑูู ุฅุฒุงู ุชูุณู/ุชูุทุน ุงููุต ุจุงุณุชุฎุฏุงู ูู ุทุฑููุฉ ูู ุงููู ุชุญุช.

- ๐ช`TokenTextSplitter`
- ๐`SentenceSplitter`

### ููุบุทู ุฏูู ูู ุฏุฑูุณ ูุงุญูุฉ

- ๐ช`SentenceWindowNodeParser`
- ๐ง`SemanticSplitterNodeParser`

## ๐ช [`TokenTextSplitter`](https://github.com/run-llama/llama_index/blob/main/llama-index-core/llama_index/core/node_parser/text/token.py)

ุงููุธููุฉ ุงูุฃุณุงุณูุฉ ูู ุชูุณูู ูุต ูุนูู ููุทุน ุฃุตุบุฑุ ูุน ุงูุชุฃูุฏ ุฅู ูู ูุทุนุฉ ุจุชุจูู ุถูู ุญุฏ ุฑููุฒ ูุญุฏุฏ.

### **ุฅุฒุงู ุจูุดุชุบู**

1. **ุงูุชุฑููุฒ (Tokenization):** ุจูุณุชุฎุฏู ูุญูู ุฑููุฒ (tokenizer) ูุชูุณูู ุงููุต ูุฑููุฒ ูุฑุฏูุฉ (ูููุงุช ุฃู ูููุงุช ูุฑุนูุฉ). ุงููุญูู ุงูุงูุชุฑุงุถู ูู ูุญูู `tiktoken` ูู GPT-3.5-Turbo.

2. **ุงูุชูุทูุน (Chunking):** ุจุนุฏูู ุจูุฌูุน ุงูุฑููุฒ ุฏู ูู ูุทุนุ ูุน ุงูุชุฃูุฏ ุฅู ุญุฌู ูู ูุทุนุฉ ุถูู ุญุฏ `chunk_size` ุงููุญุฏุฏ.

3. **ูุนุงูุฌุฉ ุงูุชุฏุงุฎู (Overlap Handling):** ููุญูุงุธ ุนูู ุงูุณูุงู ูุงูุชูุงุณู ุจูู ุงููุทุนุ ูููู ูุฏูุฌ ุชุฏุงุฎูุ ูุญุฏุฏ ุจู `chunk_overlap`ุ ุญูุซ ุขุฎุฑ ุดููุฉ ุฑููุฒ ูู ูุทุนุฉ ุจุชุชูุฑุฑ ูู ุจุฏุงูุฉ ุงููุทุนุฉ ุงููู ุจุนุฏูุง.

### ูุนุงููุงุช ูุงุฒู ุชุนุฑููุง

* **`chunk_size`**: ุจูุชุญูู ูู ุฃูุตู ุนุฏุฏ ุฑููุฒ ููู ูุทุนุฉ. ุงููููุฉ ุงูุงูุชุฑุงุถูุฉ 1024.

* **`chunk_overlap`**: ุจูุญุฏุฏ ุนุฏุฏ ุงูุฑููุฒ ุงููุชุฏุงุฎูุฉ ุจูู ุงููุทุน ุงููุชุชุงููุฉ. ุงููููุฉ ุงูุงูุชุฑุงุถูุฉ 20.

* **`separator`**: ุจูุญุฏุฏ ุงูุญุฑู ุงูุฃุณุงุณู ุงููุณุชุฎุฏู ูุชูุณูู ุงููุต ููููุงุช. ุงููููุฉ ุงูุงูุชุฑุงุถูุฉ ูุณุงูุฉ (`" "`).

* **`backup_separators`**: ุจูููุฑ ุญุฑูู ุฅุถุงููุฉ ููุชูุณูู ูู ุงููุงุตู ุงูุฃุณุงุณู ูุด ูุงูู. ุงููููุฉ ุงูุงูุชุฑุงุถูุฉ ุญุฑู ุณุทุฑ ุฌุฏูุฏ (`"\n"`).

ููุญูุธุฉ: ุชุฑุชูุจ ุงูุชูุณูู ูู: 1. ูุณู ุจุงููุงุตูุ 2. ูุณู ุจุงูููุงุตู ุงูุงุญุชูุงุทูุฉ (ูู ููุฌูุฏุฉ)ุ 3. ูุณู ุจุงูุญุฑูู

* **`include_metadata`**: ุจููุนู ุฃู ูุนุทู ุชุถููู ุงูุจูุงูุงุช ุงููุตููุฉ ุถูู ูู ูุทุนุฉ. ุงููููุฉ ุงูุงูุชุฑุงุถูุฉ `True`.

* **`include_prev_next_rel`**: ุจููุนู ุฃู ูุนุทู ุชุชุจุน ุงูุนูุงูุฉ ุจูู ุงูุนูุฏ. ุงููููุฉ ุงูุงูุชุฑุงุถูุฉ `True`.

### ูุซุงู ุนูู ุงูุงุณุชุฎุฏุงู

ููุท ุงูุงุณุชุฎุฏุงู ุงูุฃุณุงุณู ูุงูุชุงูู (ูุด ูุญุชุงุฌ ุชูุฑุฑ ุฃู ุญุงุฌุฉ ูู ุนุงูุฒ ุชุญุชูุธ ุจุงูููู ุงูุงูุชุฑุงุถูุฉ):

```python
from llama_index.core.node_parser import TokenTextSplitter

splitter = TokenTextSplitter()

nodes = splitter.get_nodes_from_documents(documents)
```

ูุญุฏุฏ ุงุณุชูุดุงููุง ุจู `chunk_sizes = [64, 128, 256, 512]` ููุฎูู `chunk_overlap` ุซุงุจุช ุนูุฏ 16 ุฑูุฒ.

### ููุฏ ุงูุชุทุจูู

```python
senpai_documents[42].text
```

```python
from llama_index.core.node_parser import TokenTextSplitter

example_split = TokenTextSplitter(chunk_size=64, chunk_overlap=16).split_text(senpai_documents[42].text)
```

```python
example_split
```

```python
len(example_split[0].split(' '))
```

```python
import tiktoken

encoding = tiktoken.get_encoding("cl100k_base")

def num_tokens_from_string(string: str, encoding=encoding) -> int:
    """ุจุชุฑุฌุน ุนุฏุฏ ุงูุฑููุฒ ูู ูุต."""
    encoding = encoding
    num_tokens = len(encoding.encode(string))
    return num_tokens
```

```python
tokens = encoding.encode(example_split[0])

for token in tokens:
    print(encoding.decode_single_token_bytes(token))
```

```python
num_tokens_from_string(example_split[0])
```

```python
from llama_index.core.node_parser import TokenTextSplitter

def token_splitter(chunk_size, documents):
    splitter = TokenTextSplitter(
        chunk_size=chunk_size,
        chunk_overlap=16,
    )
    nodes = splitter.get_nodes_from_documents(documents)
    return nodes
```

```python
token_splitter_results = {}

chunk_sizes = [64, 128, 256, 512]

# ูุฑุฑ ุนูู ูู ุญุฌู ูุทุนุฉ ูุงุนูู ุชูุณูู ุจุงูุฑููุฒ
for size in chunk_sizes:
    key = f"token_split_chunk_size_{size}"
    token_splitter_results[key] = token_splitter(size, senpai_documents)
```

```python
for key, value in token_splitter_results.items():
    print(f"ูุน {key} ุจูุญุตู ุนูู {len(value)} ูุทุนุฉ.")
```

## ๐ [`SentenceSplitter`](https://github.com/run-llama/llama_index/blob/main/llama-index-core/llama_index/core/node_parser/text/sentence.py)

ููุงุณ `SentenceSplitter`ุ ุฒู ูุง ุงุณูู ุจููููุ ูุชุฎุตุต ูู ุชูุณูู ุงููุต ูุน ูุญุงููุฉ ุงูุญูุงุธ ุนูู ุงูุฌูู ูุงูููุฑุงุช ุงููุงููุฉ ูุน ุจุนุถูุง. ุฏู ุนูู ุนูุณ `TokenTextSplitter`ุ ุงููู ุจูุฑูุฒ ุนูู ุญุฏูุฏ ุงูุฑููุฒ.

### ุฅุฒุงู ุจูุดุชุบู

1. **ุงูุชูุณูู ุงูุฃููู**

    * ุงููุต ุจูุชูุณู ุงูุฃูู ูููุฑุงุช ุจุงุณุชุฎุฏุงู `paragraph_separator` ุงููุญุฏุฏ (ุงูุชุฑุงุถูุงู ุซูุงุซ ุญุฑูู ุณุทุฑ ุฌุฏูุฏ `"\n\n\n"`).
    
    * ูู ููุฑุฉ ุจุนุฏูู ุจุชุชูุณู ุฃูุชุฑ ุจุงุณุชุฎุฏุงู "ูุญูู ุฑููุฒ ุงูุชูุทูุน" (ุงูุชุฑุงุถูุงู [`PunktSentenceTokenizer`](https://www.nltk.org/api/nltk.tokenize.PunktSentenceTokenizer.html) ูู ููุชุจุฉ `nltk`). ุงููู ุจุดูู ุฃุณุงุณู ุจูุฏูุฑ ุนูู ุญุฏูุฏ ุงูุฌูู.
    
    * ูู ุงูุทุฑู ุฏู ูุงููุฑุชุด ุชูุณููุงุช ูุงููุฉุ ุจููุฌุฃ ูุชุนุจูุฑ ุนุงุฏู ุงุญุชูุงุทู ูุงูููุงุตู ุงูุงูุชุฑุงุถูุฉ (`CHUNKING_REGEX = "[^,.;ใ๏ผ๏ผ]+[,.;ใ๏ผ๏ผ]?"`).

2. **ุงูุชูุทูุน ูุน ูุนู ุจุงูุฌููุฉ**

    * ุงูุชูุณููุงุช ุงููุงุชุฌุฉ ุจุชุชุฌูุน ูู ูุทุนุ ูุน ุงูุญูุงุธ ุนูู ุงูุฌูู ูุน ุจุนุถูุง ูุฏุฑ ุงูุฅููุงู.
    
    * ุจูุงุฎุฏ ูู ุงูุงุนุชุจุงุฑ ุนูุงูุฉ `is_sentence` ููู ุชูุณูู ุฎูุงู ุงูุนูููุฉ ุฏู.
    
    * ุญุฌู ุงููุทุนุฉ ูุงูุชุฏุงุฎู ูุณู ุจููุนุจูุง ุฏูุฑุ ุจุณ ุญุฏูุฏ ุงูุฌูู ุจุชุงุฎุฏ ุงูุฃูุถููุฉ.

3. **ูุนุงูุฌุฉ ุงูุชุฏุงุฎู**

    * ุฒู `TokenTextSplitter`ุ ุจูุฏูุฌ ุชุฏุงุฎู ุจูู ุงููุทุน ููุญูุงุธ ุนูู ุงูุณูุงู.
    
    * ุจุณุ ุจูุนุทู ุฃููููุฉ ูุงุณุชุฎุฏุงู ุขุฎุฑ ุฌููุฉ ูุงููุฉ ููุชุฏุงุฎู ุจุฏู ุขุฎุฑ ุดููุฉ ุฑููุฒ ุจุณ.

### ูุนุงููุงุช ูุงุฒู ุชุนุฑููุง

* **`chunk_size`**: ุญุฌู ุงูุฑูุฒ ุงููุณุชูุฏู ููู ูุทุนุฉ.

* **`chunk_overlap`**: ุนุฏุฏ ุงูุฑููุฒ ุงููุชุฏุงุฎูุฉ ุจูู ุงููุทุน.

* **`separator`**: ุงููุงุตู ุงูุงูุชุฑุงุถู ููุชูุณูู (ูุซูุงูุ ูุณุงูุฉ).

* **`paragraph_separator`**: ุงููุต ุงููุณุชุฎุฏู ูุชุญุฏูุฏ ููุงุตู ุงูููุฑุงุช.

* **`secondary_chunking_regex`**: ุชุนุจูุฑ ุนุงุฏู ุงุญุชูุงุทู ููุชูุณูู ูู ุงูุทุฑู ุงูุฃุณุงุณูุฉ ูุด ูุงููุฉ.

### ูุซุงู ุนูู ุงูุงุณุชุฎุฏุงู

```python
from llama_index.core.node_parser import SentenceSplitter

splitter = SentenceSplitter(chunk_size=256, chunk_overlap=50)

nodes = splitter.get_nodes_from_documents(documents)
```

### ุงูุชู ุชุณุชุฎุฏู SentenceSplitter

* ููุง ุงูุญูุงุธ ุนูู ุงูุฌูู ูุงูููุฑุงุช ุงููุงููุฉ ูููู ุถุฑูุฑู ูููู ุงูุณูุงู.
* ููุง ุชุชุนุงูู ูุน ูุต ุญูุซ ุญุฏูุฏ ุงูุฌูู ุจุชููู ูููุฉ (ูุซูุงูุ ูุณุชูุฏุงุช ูุงููููุฉุ ุฑูุงูุงุช).
* ููุง ุชููู ุนุงูุฒ ุชุชุฌูุจ ูุฌูุฏ ุฌูู ููุณูุฑุฉ ูู ุจุฏุงูุฉ ุฃู ููุงูุฉ ุงููุทุน.

### ููุฏ ุงูุชุทุจูู

```python
from llama_index.core.node_parser import SentenceSplitter

SentenceSplitter(chunk_size=64, chunk_overlap=16).split_text(senpai_documents[42].text)
```

```python
def sentence_splitter(chunk_size, documents):
    splitter = SentenceSplitter(
        chunk_size=chunk_size,
        chunk_overlap=16,
    )
    nodes = splitter.get_nodes_from_documents(documents)
    return nodes
```

```python
sentence_splitter_results = {}

# ูุฑุฑ ุนูู ูู ุญุฌู ูุทุนุฉ ูุงุนูู ุชูุณูู ุจุงูุฌูู
for size in chunk_sizes:
    key = f"sentence_split_chunk_size_{size}"
    sentence_splitter_results[key] = sentence_splitter(size, senpai_documents)
```

```python
for key, value in sentence_splitter_results.items():
    print(f"ูุน {key} ุจูุญุตู ุนูู {len(value)} ูุทุนุฉ.")
```

### ููุฎุต: `TokenTextSplitter` ููุงุจู `SentenceSplitter`

`TokenTextSplitter` ุจููุณู ุงููุต ููุทุน ุจูุงุกู ุนูู ุนุฏุฏ ูุญุฏุฏ ูู ุงูุฑููุฒ. ุจูุณุชุฎุฏู ูุญูู ุฑููุฒ ูุชูุณูู ุงููุต ูุฑููุฒ ูุฑุฏูุฉ (ูููุงุช ุฃู ูููุงุช ูุฑุนูุฉ)ุ ูุจุนุฏูู ุจูุฌูุน ุงูุฑููุฒ ุฏู ูู ูุทุน ุจุญุฌู ูุญุฏุฏ. ูู ุงููุต ูุงุชูุณูุด ุจุงูุชุณุงูู ุนูู ุญุฌู ุงููุทุนุฉ ุงููุญุฏุฏุ ุงููุทุนุฉ ุงูุฃุฎูุฑุฉ ูุชุญุชูู ุนูู ุงูุฑููุฒ ุงููุชุจููุฉุ ุงููู ูููู ุชููู ุฃูู ูู ุญุฌู ุงููุทุนุฉ ุงููุญุฏุฏ.

`SentenceSplitter`ุ ูู ูุงุญูุฉ ุชุงููุฉุ ุจููุณู ุงููุต ููุทุน ุจูุงุกู ุนูู ุงูุฌูู. ุจูุณุชุฎุฏู ุฎูุงุฑุฒููุฉ ูุดู ุญุฏูุฏ ุงูุฌููุฉ ูุชุญุฏูุฏ ููุงู ุจุฏุงูุฉ ูููุงูุฉ ุงูุฌููุ ูุจุนุฏูู ุจูุฌูุน ุงูุฌูู ุฏู ูู ูุทุน. ุญุฌู ุงููุทุน ุฏู ูููู ูุฎุชูู ุญุณุจ ุทูู ุงูุฌูู.

## ุงุฎุชูุงุฑ ุงูุงุณุชุฑุงุชูุฌูุฉ ููุฅุฏุฎุงู

```python
import random
random.seed(0)

# ุงุฎุชุฑ ุจุดูู ุนุดูุงุฆู ููุชุงุญ ูู ูุงููุณ ูุชุงุฆุฌ ุญุฌู ุงููุทุนุฉ
strategies = list(token_splitter_results.keys()) + list(sentence_splitter_results.keys())
random_key = random.choice(strategies)
print(f"ุงูููุชุงุญ ุงููุฎุชุงุฑ ุนุดูุงุฆูุงู: {random_key}")
```

## ุงูุฅุฏุฎุงู ูู Qdrant

```python
from llama_index.core.settings import Settings
from utils import setup_llm, setup_embed_model, setup_vector_store

COLLECTION_NAME = "wots_sentence_split_chunk_size_256"

setup_llm(
    provider="openai",
    api_key=OPENAI_API_KEY,
    temperature=0.75,
    model="gpt-4o",
    system_prompt="""ุงุณุชุฎุฏู ุงูุณูุงู ุงูููุฏู ููุท ูุงููุฏ ุฅุฌุงุจุฉ ูุงููุฉ ููุชูุงุณูุฉ ูุงุณุชุนูุงู ุงููุณุชุฎุฏู.
    ุฅุฌุงุจุชู ูุงุฒู ุชููู ูุจููุฉ ุนูู ุงูุณูุงู ุงูููุฏู ูุฐุงุช ุตูุฉ ุจุฌููุฑ ุงุณุชุนูุงู ุงููุณุชุฎุฏู.
    """
)

setup_embed_model(
    provider="openai",
    model="text-embedding-3-small",
    api_key=OPENAI_API_KEY
)

vector_store = setup_vector_store(QDRANT_URL, QDRANT_API_KEY, COLLECTION_NAME)
```

```python
from utils import ingest

# ุฅูู ุงูููุณู ุงููู ููุณุชุฎุฏููุ
sent_splitter = SentenceSplitter(chunk_size=256, chunk_overlap=16)

transforms = [sent_splitter, Settings.embed_model]

split_nodes = ingest(
    documents=senpai_documents,
    transformations=transforms,
    vector_store=vector_store
)
```

## ุจูุงุก ุงูููุฑุณ ููู VectorStore

```python
from llama_index.core import StorageContext
from utils import create_index

index = create_index(
    from_where="vector_store",
    embed_model=Settings.embed_model,
    vector_store=vector_store,
)
```

## ุฅูุดุงุก ูุญุฑู ุงูุงุณุชุนูุงู

ูุถุน ุงูุงุณุชุฌุงุจุฉ ุงูุงูุชุฑุงุถู ููุญุฑู ุงูุงุณุชุนูุงู ูู `refine` ุงููู ุจููุดุฆ ููุญุณู ุฅุฌุงุจุฉ ุนู ุทุฑูู ุงููุฑูุฑ ุจุงูุชุชุงุจุน ุนูู ูู ูุทุนุฉ ูุต ูุณุชุฑุฌุนุฉ. ุฏู ุจูุนูู ุงุณุชุฏุนุงุก LLM ูููุตู ููู ุนูุฏุฉ/ูุทุนุฉ ูุณุชุฑุฌุนุฉ.

ุฃูุง ุจุบูุฑ ูุถุน ุงูุงุณุชุฌุงุจุฉ ูู `compact`ุ ุงููู ุดุจู refine ุจุณ ุจูุฏูุฌ ุงููุทุน ููุฏูุงูุ ููุง ูุคุฏู ูุงุณุชุฏุนุงุกุงุช LLM ุฃูู.

ุชูุฏุฑ [ุชุฒูุฑ ูุณุชูุฏุงุช LlamaIndex](https://docs.llamaindex.ai/en/stable/module_guides/querying/response_synthesizers/) ูุชุชุนูู ุฃูุชุฑ ุนู ุงูุฎูุงุฑุงุช ุงููุชุงุญุฉ ููู ููุง. ุจุณ ุฎุฏ ุจุงูู ุฅู ุฏู ููุงู ูุนุงูู ุชุญุช ุณูุทุฑุชูุ ูุงููู ููุงู ููุฃุซุฑ ุนูู ุงูุชูููุฏ ุจุชุงุนู.

ูุณูุจ ุฏู ููู ุชุฌุฑุจ ููู.

ุฃูุง ููุงู ูุบูุฑ ูููุฉ `similiarty_top_k` ูู ูููุชูุง ุงูุงูุชุฑุงุถูุฉ 2 ูู 5. ุฏู ุงุฎุชูุงุฑ ุชุนุณูู ูุงููุฏู ููู ุจุณ ุชูุถูุญ ุฅูู ูุนุงูู ุชุญุช ุณูุทุฑุชู ูุงููู ููุฃุซุฑ ุนูู ูุชุงุฆุฌ ุงูุชูููุฏ ุจุชุงุนู. ุฒูุงุฏุฉ ุงููููุฉ ุฏู ูุนูุงูุง ุฅูู ูุชุฒูุฏ ุงุญุชูุงููุฉ ุฌูุจ ุฃูุชุฑ ุงููุณุชูุฏุงุช ุฐุงุช ุงูุตูุฉ ูู ูุงุนุฏุฉ ุงูุจูุงูุงุช ุงููุชุฌูุฉ.

### ูุถุน ุงุณุชุนูุงู ูุฎุฒู ุงููุชุฌูุงุช

ูุญุฑู ุงูุงุณุชุนูุงู ููุงู ุนูุฏู ูุนุงูู ูู `vector_store_query_mode`ุ ูู [ุฎูุงุฑุงุช ูุชุนุฏุฏุฉ ุชูุฏุฑ ุชุฎุชุงุฑ ูููุง ููุง](https://github.com/run-llama/llama_index/blob/main/llama-index-core/llama_index/core/vector_stores/types.py).

`ุงูููุงุกูุฉ ุงููุงูุดูุฉ ุงููุตูู (MMR)` ุจุชูุงุฒู ุจูู ุงูููุงุกูุฉ ูุงูุชููุน ุนูุฏ ุงุฎุชูุงุฑ ูุฌููุนุฉ ูุฑุนูุฉ ูู ุงูุนูุงุตุฑ ูู ูุฌููุนุฉ ุฃูุจุฑ.

ุงูููุฑุฉ ุงูุฃุณุงุณูุฉ ูุฑุงุก MMR ูู ุงุฎุชูุงุฑ ุงูุนูุงุตุฑ ุจุดูู ูุชูุฑุฑ ุงููู ุชููู ุฐุงุช ุตูุฉ ุนุงููุฉ ุจุงูุงุณุชุนูุงู ูููุงู ูุฎุชููุฉ ุนู ุงูุนูุงุตุฑ ุงููุฎุชุงุฑุฉ ุจุงููุนู. ุฏู ุจูุชุญูู ุนู ุทุฑูู ุชุนุธูู ูุชูุฌุฉ ุจุชุฌูุน ูููููู:

1. **ุงูููุงุกูุฉ**: ุงูุชุดุงุจู ุจูู ุงูุนูุตุฑ ูุงูุงุณุชุนูุงู (ูุซูุงู ุชุดุงุจู ุฌูุจ ุงูุชูุงู)

2. **ุงูุชููุน**: ุฃูุตู ุชุดุงุจู ุจูู ุงูุนูุตุฑ ูุฃู ูู ุงูุนูุงุตุฑ ุงููุฎุชุงุฑุฉ ุจุงููุนู

ูุชูุฌุฉ MMR ูู ูุฒูุฌ ุฎุทู ูู ุงูููููุงุช ุฏูุ ูุชุญูู ูููุง ุจูุนุงูู `ฮป` (ูุงูุจุฏุง) ุงููู ุจูุญุฏุฏ ุงูููุงุถูุฉ ุจูู ุงูููุงุกูุฉ ูุงูุชููุน:

`MMR = argmax [ฮป * Relevance(item, query) - (1-ฮป) * max(Similarity(item, selected_item))]`

- ูู ฮป ูุฑูุจุฉ ูู 1ุ MMR ุจุชุฑูุฒ ุฃูุชุฑ ุนูู ุงูููุงุกูุฉ.
- ูู ฮป ูุฑูุจุฉ ูู 0ุ MMR ุจุชูุถู ุงูุชููุน.

MMR ูููู ุชุญุณู ูููู ุงูุงุณุชุฑุฌุงุน ุนู ุทุฑูู ุงุฎุชูุงุฑ ูุฌููุนุฉ ูุชููุนุฉ ูู ุงูููุงุทุน ุฐุงุช ุงูุตูุฉ. ุฏู ุจูุณุงุนุฏ ูู ุงูุชูุงุท ุฌูุงูุจ ูุฎุชููุฉ ูู ุงูุงุณุชุนูุงู ูุจูููุฑ ููููุฐุฌ ุงููุบุฉ ุณูุงู ุฃุบูู ูุชูููุฏ ุงูุฅุฌุงุจุฉ ุงูููุงุฆูุฉ.

ููุงุฆุฏ ุงุณุชุฎุฏุงู MMR ูู RAG ุจุชุดูู:

1. ุชุฌูุจ ุงุฎุชูุงุฑ ููุงุทุน ุจุชุญุชูู ุนูู ูุนูููุงุช ูุชุดุงุจูุฉ ุฌุฏุงู.
2. ุฒูุงุฏุฉ ูุฑุต ุชุบุทูุฉ ุฌูุงูุจ ูุฎุชููุฉ ูู ุงูุงุณุชุนูุงู.
3. ุชูููุฑ ูููุฐุฌ ุงููุบุฉ ุจูุฌููุนุฉ ูุชููุนุฉ ูู ุงูููุงุทุน ุฐุงุช ุงูุตูุฉ ูููู ูุคุฏู ูุฅุฌุงุจุงุช ุฃูุชุฑ ุดูููุงู ููุชูุงุฒูุฉ.

### ูุณูุจ ููู ุชุฌุฑุจ ุงุณุชุฎุฏุงู MMR (ุฃูุ ุนุฏู ุงุณุชุฎุฏุงููุง) ูููุงู ุชุฌุฑุจ ููู ฮป ูุฎุชููุฉ.

ุงูููุท ูุฅุฒุงู ุชุณุชุฎุฏููุง ููุฌูุฏ ุนุดุงู ุชุดููู.

```python
from utils import create_query_engine

query_engine = create_query_engine(
    index=index,
    mode="query",
    response_mode="compact",
    similiarty_top_k=5,
    vector_store_query_mode="mmr",
    vector_store_kwargs={"mmr_threshold": 0.42}
)
```

### ูููุฏุฑุด ููุณู ุงูู prompt!

```python
from utils import display_prompt_dict
display_prompt_dict(query_engine.get_prompts())
```

```python
from prompts import ANSWER_GEN_PROMPT

print(ANSWER_GEN_PROMPT)
```

```python
from llama_index.core import PromptTemplate

ANSWER_GEN_PROMPT_TEMPLATE = PromptTemplate(ANSWER_GEN_PROMPT)

query_engine.update_prompts({'response_synthesizer:text_qa_template': ANSWER_GEN_PROMPT_TEMPLATE})
```

```python
display_prompt_dict(query_engine.get_prompts())
```

### ุฅูุดุงุก ุฎุท ุฃูุงุจูุจ ุงูุงุณุชุนูุงู

```python
from utils import create_query_pipeline
from llama_index.core.query_pipeline import InputComponent

input_component = InputComponent()

chain = [input_component, query_engine]

query_pipeline = create_query_pipeline(chain)
```

```python
Settings.llm
```

```python
query_pipeline.run(input="ุฅุฒุงู ุฃูุฏุฑ ุฃุจูู ุงูุฃูุถู ูู ุงูุนุงูู ูู ุงููู ุจุงุนูููุ")
```

```python
query_pipeline.run(input="ุฅุฒุงู ุฃูุฏุฑ ุฃุจูู ุงูุนูุงูุฉ ุงูุชุฌุงุฑูุฉ ุจุชุงุนุชู ูุฃุนูู ุงุณู ูููุณู ุนุดุงู ุฃุจูู ูุคูู ุจุดูู ูุฑูุฏ ูููุฑุต ุงููุงุดุฆุฉ ูู ุงูุชูููููุฌูุงุ")
```

```python
query_pipeline.run(input="ุฅุฒุงู ุฃูุฏุฑ ุฃุนูู ุฃูุธูุฉ ุนุดุงู ุฃุจูู ุฃูุฌุญ ูุณุฎุฉ ูู ููุณู ูุน ุฅูู ุฃุดุชุบู ุจุฃูู ูุฌููุฏ ููููุ")
```

</div>
